{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2895e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /root/.venv/bin/python\n",
      "Python version: 3.11.14 (main, Oct 14 2025, 21:26:53) [Clang 20.1.4 ]\n",
      "Using UV environment: True\n"
     ]
    }
   ],
   "source": [
    "# Verify kernel is using the correct environment\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Using UV environment: {'/root/.venv' in sys.executable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e781e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "# Force CPU to avoid GPU memory issues with large graphs\n",
    "os.environ.setdefault('JAX_PLATFORMS', 'cpu')\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add tools directory to path\n",
    "sys.path.insert(0, str(Path.cwd() / 'tools'))\n",
    "\n",
    "from tv_graph import TVGraph\n",
    "from thrml import Block, BlockGibbsSpec, FactorSamplingProgram, SamplingSchedule, sample_states\n",
    "from thrml.block_management import block_state_to_global\n",
    "from thrml.block_sampling import sample_blocks\n",
    "from thrml.models import CategoricalEBMFactor, CategoricalGibbsConditional\n",
    "from thrml.models.ebm import DEFAULT_NODE_SHAPE_DTYPES\n",
    "from thrml.pgm import CategoricalNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf1427",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "INPUT_FOLDER = Path(\"input/fcc-seed87-st50-ch30-post-auction-50st-15ch\")\n",
    "LAMBDA_CONFLICT = 8.0\n",
    "LAMBDA_DOMAIN = 100.0\n",
    "WARMUP_STEPS = 200\n",
    "NUM_SAMPLES = 200\n",
    "STEPS_PER_SAMPLE = 1\n",
    "SEED = 0\n",
    "\n",
    "# Blocking strategy parameters\n",
    "BLOCK_SIZE_GEOGRAPHIC = 5  # Stations per geographic block\n",
    "BLOCK_SIZE_RANDOM = 3      # Stations per random block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66042c63",
   "metadata": {},
   "source": [
    "## Load Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb842d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = TVGraph(INPUT_FOLDER)\n",
    "print(f\"Loaded graph with {graph.station_count:,} stations and {graph.channel_count:,} channels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49acba9",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_domain_factor(graph: TVGraph, nodes: list[CategoricalNode], penalty: float) -> CategoricalEBMFactor:\n",
    "    station_count = len(nodes)\n",
    "    channel_count = graph.channel_count\n",
    "    weights = np.full((station_count, channel_count), -float(penalty), dtype=np.float32)\n",
    "    for station in graph.stations_by_id.values():\n",
    "        if station.station_index is None:\n",
    "            raise ValueError(f\"Station {station.station_id} is missing a contiguous index.\")\n",
    "        weights[station.station_index, station.domain_indices] = 0.0\n",
    "    return CategoricalEBMFactor([Block(nodes)], jnp.asarray(weights))\n",
    "\n",
    "\n",
    "def make_interference_factor(\n",
    "    graph: TVGraph, nodes: list[CategoricalNode], penalty: float\n",
    ") -> CategoricalEBMFactor | None:\n",
    "    seen: set[tuple[int, int, int, int]] = set()\n",
    "    constraint_rows: list[tuple[int, int, int, int]] = []\n",
    "    for station in graph.stations_by_id.values():\n",
    "        if station.station_index is None:\n",
    "            continue\n",
    "        a_idx = station.station_index\n",
    "        for interference, partner_idx in station.interferences_deduped():\n",
    "            a_chan_idx = interference.subject_channel_index\n",
    "            b_chan_idx = interference.other_channel_index\n",
    "            key = (a_idx, partner_idx, a_chan_idx, b_chan_idx)\n",
    "            if key in seen:\n",
    "                raise ValueError(f\"Duplicate constraint: {key}\")\n",
    "            seen.add(key)\n",
    "            constraint_rows.append(key)\n",
    "\n",
    "    if not constraint_rows:\n",
    "        return None\n",
    "\n",
    "    channel_count = graph.channel_count\n",
    "    edge_count = len(constraint_rows)\n",
    "    weights = np.zeros((edge_count, channel_count, channel_count), dtype=np.float32)\n",
    "    head_nodes: list[CategoricalNode] = []\n",
    "    tail_nodes: list[CategoricalNode] = []\n",
    "\n",
    "    for idx, (a_idx, b_idx, a_chan_idx, b_chan_idx) in enumerate(constraint_rows):\n",
    "        head_nodes.append(nodes[a_idx])\n",
    "        tail_nodes.append(nodes[b_idx])\n",
    "        weights[idx, a_chan_idx, b_chan_idx] = -float(penalty)\n",
    "\n",
    "    return CategoricalEBMFactor([Block(head_nodes), Block(tail_nodes)], jnp.asarray(weights))\n",
    "\n",
    "\n",
    "def prepare_initial_state(\n",
    "    graph: TVGraph, free_blocks: list[Block], seed: int\n",
    ") -> tuple[list[jnp.ndarray], int, int]:\n",
    "    \"\"\"Build initial state for blocks (each block may contain multiple nodes).\"\"\"\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "    init_state: list[jnp.ndarray] = []\n",
    "    post_count = 0\n",
    "    random_count = 0\n",
    "    \n",
    "    for block in free_blocks:\n",
    "        block_channels = []\n",
    "        for node in block.nodes:\n",
    "            # Find station index for this node\n",
    "            station_index = None\n",
    "            for idx, n in enumerate(nodes):\n",
    "                if n is node:\n",
    "                    station_index = idx\n",
    "                    break\n",
    "            \n",
    "            if station_index is None:\n",
    "                raise ValueError(\"Could not find station index for node\")\n",
    "            \n",
    "            station_id = graph.station_id_for_index(station_index)\n",
    "            station = graph.station(station_id)\n",
    "            new_channel = station.new_channel\n",
    "            \n",
    "            if new_channel is not None:\n",
    "                if new_channel not in graph.channel_values:\n",
    "                    channel_idx = graph.channel_count - 1\n",
    "                else:\n",
    "                    channel_idx = graph.channel_index_for_channel(new_channel)\n",
    "                post_count += 1\n",
    "            else:\n",
    "                domain = np.asarray(station.domain_indices, dtype=np.int32)\n",
    "                if domain.size == 0:\n",
    "                    raise ValueError(f\"Station {station.station_id} has an empty domain.\")\n",
    "                key, subkey = jax.random.split(key)\n",
    "                channel_idx = int(jax.random.choice(subkey, domain))\n",
    "                random_count += 1\n",
    "            \n",
    "            block_channels.append(channel_idx)\n",
    "        \n",
    "        init_state.append(jnp.asarray(block_channels, dtype=jnp.uint8))\n",
    "    \n",
    "    return init_state, post_count, random_count\n",
    "\n",
    "\n",
    "def block_assignment_to_array(block_state: list[jnp.ndarray]) -> np.ndarray:\n",
    "    \"\"\"Flatten block state to array (handles multi-node blocks).\"\"\"\n",
    "    assignments = []\n",
    "    for block in block_state:\n",
    "        block_arr = np.asarray(block, dtype=np.int32)\n",
    "        if block_arr.ndim == 0:\n",
    "            assignments.append(int(block_arr))\n",
    "        else:\n",
    "            assignments.extend(block_arr.tolist())\n",
    "    return np.asarray(assignments, dtype=np.int32)\n",
    "\n",
    "\n",
    "def evaluate_energy(program: FactorSamplingProgram, factors: list[CategoricalEBMFactor], block_state: list[jnp.ndarray]) -> float:\n",
    "    global_state = block_state_to_global(list(block_state), program.gibbs_spec)\n",
    "    total = 0.0\n",
    "    for factor in factors:\n",
    "        total += float(factor.energy(global_state, program.gibbs_spec))\n",
    "    return total\n",
    "\n",
    "\n",
    "def score_assignment(graph: TVGraph, assignment: np.ndarray) -> dict[str, object]:\n",
    "    channel_values = graph.channel_for_channel_id\n",
    "    domain_mask = graph.domain_mask\n",
    "    domain_violations = 0\n",
    "    for station_index, channel_index in enumerate(assignment):\n",
    "        if not domain_mask[station_index, channel_index]:\n",
    "            domain_violations += 1\n",
    "\n",
    "    violations = 0\n",
    "    violations_by_type: Counter[str] = Counter()\n",
    "    seen_pairs: set[tuple[int, int, int, int]] = set()\n",
    "\n",
    "    for station in graph.stations_by_id.values():\n",
    "        if station.station_index is None:\n",
    "            continue\n",
    "        a_idx = station.station_index\n",
    "        assigned_a_idx = int(assignment[a_idx])\n",
    "        assigned_a_val = channel_values[assigned_a_idx]\n",
    "\n",
    "        for interference in station.interferences:\n",
    "            if assigned_a_val != interference.subject_channel:\n",
    "                continue\n",
    "            for partner_idx in interference.station_indices:\n",
    "                assigned_b_idx = int(assignment[partner_idx])\n",
    "                assigned_b_val = channel_values[assigned_b_idx]\n",
    "                if assigned_b_val != interference.other_channel:\n",
    "                    continue\n",
    "\n",
    "                if a_idx <= partner_idx:\n",
    "                    key = (a_idx, partner_idx, assigned_a_idx, assigned_b_idx)\n",
    "                    constraint_type = interference.constraint_type\n",
    "                else:\n",
    "                    key = (partner_idx, a_idx, assigned_b_idx, assigned_a_idx)\n",
    "                    constraint_type = interference.constraint_type\n",
    "\n",
    "                if key in seen_pairs:\n",
    "                    continue\n",
    "                seen_pairs.add(key)\n",
    "                violations += 1\n",
    "                violations_by_type[constraint_type] += 1\n",
    "\n",
    "    return {\n",
    "        \"domain_violations\": domain_violations,\n",
    "        \"violations\": violations,\n",
    "        \"violations_by_type\": violations_by_type,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9edee",
   "metadata": {},
   "source": [
    "## Blocking Strategy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50701181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_node_blocks(nodes: list[CategoricalNode]) -> list[Block]:\n",
    "    \"\"\"Strategy 1: One node per block (baseline).\"\"\"\n",
    "    return [Block([node]) for node in nodes]\n",
    "\n",
    "\n",
    "def create_geographic_blocks(nodes: list[CategoricalNode], block_size: int) -> list[Block]:\n",
    "    \"\"\"Strategy 2: Group consecutive stations (assumes stations are ordered geographically).\"\"\"\n",
    "    blocks = []\n",
    "    for i in range(0, len(nodes), block_size):\n",
    "        block_nodes = nodes[i:i+block_size]\n",
    "        if block_nodes:  # Handle remainder\n",
    "            blocks.append(Block(block_nodes))\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def create_random_blocks(nodes: list[CategoricalNode], block_size: int, seed: int) -> list[Block]:\n",
    "    \"\"\"Strategy 3: Randomly shuffle and group stations.\"\"\"\n",
    "    shuffled = nodes.copy()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(shuffled)\n",
    "    \n",
    "    blocks = []\n",
    "    for i in range(0, len(shuffled), block_size):\n",
    "        block_nodes = shuffled[i:i+block_size]\n",
    "        if block_nodes:\n",
    "            blocks.append(Block(block_nodes))\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dcf776",
   "metadata": {},
   "source": [
    "## Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac240b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sampling(\n",
    "    graph: TVGraph,\n",
    "    free_blocks: list[Block],\n",
    "    strategy_name: str,\n",
    "    lambda_conflict: float,\n",
    "    lambda_domain: float,\n",
    "    warmup_steps: int,\n",
    "    num_samples: int,\n",
    "    seed: int,\n",
    ") -> tuple[np.ndarray, dict, float, float]:\n",
    "    \"\"\"Run sampling with given blocking strategy and return best sample.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Strategy: {strategy_name}\")\n",
    "    print(f\"Number of blocks: {len(free_blocks)}\")\n",
    "    block_sizes = [len(block.nodes) for block in free_blocks]\n",
    "    print(f\"Block sizes: min={min(block_sizes)}, max={max(block_sizes)}, avg={np.mean(block_sizes):.1f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Build factors\n",
    "    domain_factor = make_domain_factor(graph, nodes, penalty=lambda_domain)\n",
    "    conflict_factor = make_interference_factor(graph, nodes, penalty=lambda_conflict)\n",
    "    factors = [domain_factor, conflict_factor] if conflict_factor else [domain_factor]\n",
    "    \n",
    "    # Build sampling program\n",
    "    gibbs_spec = BlockGibbsSpec(\n",
    "        free_super_blocks=free_blocks,\n",
    "        clamped_blocks=[],\n",
    "        node_shape_dtypes=DEFAULT_NODE_SHAPE_DTYPES,\n",
    "    )\n",
    "    samplers = [CategoricalGibbsConditional(graph.channel_count) for _ in free_blocks]\n",
    "    program = FactorSamplingProgram(gibbs_spec, samplers, factors, other_interaction_groups=[])\n",
    "    \n",
    "    # Initialize\n",
    "    init_state, post_count, random_count = prepare_initial_state(graph, free_blocks, seed)\n",
    "    print(f\"Initial state: {post_count} post-auction, {random_count} random\")\n",
    "    \n",
    "    initial_assignment = block_assignment_to_array(init_state)\n",
    "    init_energy = evaluate_energy(program, factors, init_state)\n",
    "    init_stats = score_assignment(graph, initial_assignment)\n",
    "    print(f\"Initial: energy={init_energy:.2f}, violations={init_stats['violations']}, \"\n",
    "          f\"domain breaches={init_stats['domain_violations']}\")\n",
    "    \n",
    "    # Sample\n",
    "    key = jax.random.PRNGKey(seed ^ 0xFEED5EED)\n",
    "    state_free = [jnp.asarray(block) for block in init_state]\n",
    "    clamp_state = []\n",
    "    sampler_states = [sampler.init() for sampler in samplers]\n",
    "    \n",
    "    samples = []\n",
    "    \n",
    "    # Warmup\n",
    "    for i in range(warmup_steps):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        state_free, sampler_states = sample_blocks(subkey, state_free, clamp_state, program, sampler_states)\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  Warmup step {i + 1}/{warmup_steps}\")\n",
    "    \n",
    "    samples.append(block_assignment_to_array(state_free))\n",
    "    \n",
    "    # Sampling\n",
    "    for i in range(1, num_samples):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        state_free, sampler_states = sample_blocks(subkey, state_free, clamp_state, program, sampler_states)\n",
    "        samples.append(block_assignment_to_array(state_free))\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  Sample {i + 1}/{num_samples}\")\n",
    "    \n",
    "    samples_array = np.stack(samples, axis=0)\n",
    "    \n",
    "    # Find best\n",
    "    best_index = 0\n",
    "    best_assignment = samples_array[0]\n",
    "    best_stats = score_assignment(graph, best_assignment)\n",
    "    best_energy = evaluate_energy(program, factors, [jnp.asarray([val], dtype=jnp.uint8) for val in best_assignment])\n",
    "    \n",
    "    for idx in range(1, len(samples_array)):\n",
    "        assignment = samples_array[idx]\n",
    "        stats = score_assignment(graph, assignment)\n",
    "        energy = evaluate_energy(program, factors, [jnp.asarray([val], dtype=jnp.uint8) for val in assignment])\n",
    "        if stats[\"violations\"] < best_stats[\"violations\"] or (\n",
    "            stats[\"violations\"] == best_stats[\"violations\"] and energy < best_energy\n",
    "        ):\n",
    "            best_index = idx\n",
    "            best_stats = stats\n",
    "            best_energy = energy\n",
    "    \n",
    "    print(f\"\\nBest sample #{best_index}: energy={best_energy:.2f}, \"\n",
    "          f\"violations={best_stats['violations']}, \"\n",
    "          f\"domain breaches={best_stats['domain_violations']}\")\n",
    "    \n",
    "    return best_assignment, best_stats, best_energy, init_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f5540",
   "metadata": {},
   "source": [
    "## Create Nodes and Run All Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec2988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nodes (shared across all strategies)\n",
    "nodes = [CategoricalNode() for _ in graph.station_ids_by_index]\n",
    "print(f\"Created {len(nodes)} categorical nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a88ec5",
   "metadata": {},
   "source": [
    "### Strategy 1: Single-Node Blocks (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_single = create_single_node_blocks(nodes)\n",
    "\n",
    "best_single, stats_single, energy_single, init_energy_single = run_sampling(\n",
    "    graph=graph,\n",
    "    free_blocks=blocks_single,\n",
    "    strategy_name=\"Single-Node Blocks\",\n",
    "    lambda_conflict=LAMBDA_CONFLICT,\n",
    "    lambda_domain=LAMBDA_DOMAIN,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664087c3",
   "metadata": {},
   "source": [
    "### Strategy 2: Geographic Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_geographic = create_geographic_blocks(nodes, BLOCK_SIZE_GEOGRAPHIC)\n",
    "\n",
    "best_geo, stats_geo, energy_geo, init_energy_geo = run_sampling(\n",
    "    graph=graph,\n",
    "    free_blocks=blocks_geographic,\n",
    "    strategy_name=f\"Geographic Blocks (size={BLOCK_SIZE_GEOGRAPHIC})\",\n",
    "    lambda_conflict=LAMBDA_CONFLICT,\n",
    "    lambda_domain=LAMBDA_DOMAIN,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a74028",
   "metadata": {},
   "source": [
    "### Strategy 3: Random Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_random = create_random_blocks(nodes, BLOCK_SIZE_RANDOM, SEED)\n",
    "\n",
    "best_random, stats_random, energy_random, init_energy_random = run_sampling(\n",
    "    graph=graph,\n",
    "    free_blocks=blocks_random,\n",
    "    strategy_name=f\"Random Blocks (size={BLOCK_SIZE_RANDOM})\",\n",
    "    lambda_conflict=LAMBDA_CONFLICT,\n",
    "    lambda_domain=LAMBDA_DOMAIN,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_interference = create_interference_blocks(graph, nodes, BLOCK_SIZE_INTERFERENCE)\n",
    "\n",
    "best_interference, stats_interference, energy_interference, init_energy_interference = run_sampling(\n",
    "    graph=graph,\n",
    "    free_blocks=blocks_interference,\n",
    "    strategy_name=f\"Interference Blocks (max_size={BLOCK_SIZE_INTERFERENCE})\",\n",
    "    lambda_conflict=LAMBDA_CONFLICT,\n",
    "    lambda_domain=LAMBDA_DOMAIN,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    num_samples=NUM_SAMPLES,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0743017f",
   "metadata": {},
   "source": [
    "### Strategy 4: Interference-Based Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae7e1c7",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ccbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    {\n",
    "        \"Strategy\": \"Single-Node Blocks\",\n",
    "        \"Block Count\": len(blocks_single),\n",
    "        \"Avg Block Size\": 1.0,\n",
    "        \"Initial Energy\": init_energy_single,\n",
    "        \"Best Energy\": energy_single,\n",
    "        \"Energy Improvement\": init_energy_single - energy_single,\n",
    "        \"Violations\": stats_single[\"violations\"],\n",
    "        \"Domain Breaches\": stats_single[\"domain_violations\"],\n",
    "    },\n",
    "    {\n",
    "        \"Strategy\": f\"Geographic Blocks (size={BLOCK_SIZE_GEOGRAPHIC})\",\n",
    "        \"Block Count\": len(blocks_geographic),\n",
    "        \"Avg Block Size\": np.mean([len(b.nodes) for b in blocks_geographic]),\n",
    "        \"Initial Energy\": init_energy_geo,\n",
    "        \"Best Energy\": energy_geo,\n",
    "        \"Energy Improvement\": init_energy_geo - energy_geo,\n",
    "        \"Violations\": stats_geo[\"violations\"],\n",
    "        \"Domain Breaches\": stats_geo[\"domain_violations\"],\n",
    "    },\n",
    "    {\n",
    "        \"Strategy\": f\"Random Blocks (size={BLOCK_SIZE_RANDOM})\",\n",
    "        \"Block Count\": len(blocks_random),\n",
    "        \"Avg Block Size\": np.mean([len(b.nodes) for b in blocks_random]),\n",
    "        \"Initial Energy\": init_energy_random,\n",
    "        \"Best Energy\": energy_random,\n",
    "        \"Energy Improvement\": init_energy_random - energy_random,\n",
    "        \"Violations\": stats_random[\"violations\"],\n",
    "        \"Domain Breaches\": stats_random[\"domain_violations\"],\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON OF BLOCKING STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07198373",
   "metadata": {},
   "source": [
    "## Visualization Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d094883",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "strategies = [\n",
    "    (\"Single-Node\", stats_single),\n",
    "    (f\"Geographic (size={BLOCK_SIZE_GEOGRAPHIC})\", stats_geo),\n",
    "    (f\"Random (size={BLOCK_SIZE_RANDOM})\", stats_random),\n",
    "]\n",
    "\n",
    "for ax, (name, stats) in zip(axes, strategies):\n",
    "    violations = stats[\"violations\"]\n",
    "    domain_breaches = stats[\"domain_violations\"]\n",
    "    \n",
    "    categories = ['Violations', 'Domain\\nBreaches']\n",
    "    values = [violations, domain_breaches]\n",
    "    colors = ['#e74c3c' if v > 0 else '#27ae60' for v in values]\n",
    "    \n",
    "    ax.bar(categories, values, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f\"{name}\\n({violations} violations)\", fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (cat, val) in enumerate(zip(categories, values)):\n",
    "        ax.text(i, val + max(values) * 0.02, str(val), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Interpretation:\")\n",
    "print(\"- Lower violations = better solution quality\")\n",
    "print(\"- Multi-node blocks may converge faster but with different final quality\")\n",
    "print(\"- Geographic blocks leverage spatial structure\")\n",
    "print(\"- Random blocks provide mixing without spatial bias\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
